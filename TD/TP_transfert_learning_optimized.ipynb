{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3dd59f5",
   "metadata": {},
   "source": [
    "# TP — Transfer Learning (ResNet50) sur ShipsNet (Kaggle)\n",
    "\n",
    "Objectifs :\n",
    "1. Charger le dataset **Ships in Satellite Imagery (ShipsNet)** depuis Kaggle (via `kagglehub`).\n",
    "2. Préparer les données (décodage JSON, split train/val/test, pré-traitement ResNet50).\n",
    "3. Construire un modèle **ResNet50** pré-entraîné (ImageNet) + tête de classification.\n",
    "4. Entraîner en 2 phases : **(i) head-only** puis **(ii) fine-tuning**.\n",
    "5. Évaluer : accuracy, matrice de confusion, rapport de classification.\n",
    "\n",
    "> Remarque : notebook conçu pour être exécutable “Run all”.  \n",
    "> Si vous exécutez dans un environnement sans accès réseau, téléchargez le dataset localement et pointez `DATA_DIR`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fe2300",
   "metadata": {},
   "source": [
    "## 0. Imports et reproductibilité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8859195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers as L\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "SEED = 42\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497a9edc",
   "metadata": {},
   "source": [
    "## 1. Téléchargement et localisation du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e9679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A (recommandée) : téléchargement via kagglehub\n",
    "# Requiert accès internet + éventuelle config Kaggle (selon environnement).\n",
    "\n",
    "USE_KAGGLEHUB = True\n",
    "DATA_DIR = None\n",
    "\n",
    "if USE_KAGGLEHUB:\n",
    "    try:\n",
    "        import kagglehub\n",
    "        DATA_DIR = Path(kagglehub.dataset_download(\"rhammell/ships-in-satellite-imagery\"))\n",
    "        print(\"Dataset téléchargé dans :\", DATA_DIR)\n",
    "    except Exception as e:\n",
    "        print(\"Téléchargement via kagglehub a échoué:\", repr(e))\n",
    "        USE_KAGGLEHUB = False\n",
    "\n",
    "if not USE_KAGGLEHUB:\n",
    "    # Option B : chemin local (à adapter)\n",
    "    # DATA_DIR = Path(\"/path/to/shipsnet\")\n",
    "    raise ValueError(\"Définissez DATA_DIR manuellement si USE_KAGGLEHUB=False.\")\n",
    "\n",
    "assert DATA_DIR is not None and DATA_DIR.exists(), \"DATA_DIR invalide. Vérifiez téléchargement / chemin.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691fb79c",
   "metadata": {},
   "source": [
    "## 2. Chargement de ShipsNet (JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1066823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_shipsnet_json(root: Path) -> Path:\n",
    "    candidates = []\n",
    "    for p in root.rglob(\"*.json\"):\n",
    "        name = p.name.lower()\n",
    "        if \"shipsnet\" in name or (\"ship\" in name and \"net\" in name):\n",
    "            candidates.append(p)\n",
    "    if not candidates:\n",
    "        all_json = list(root.rglob(\"*.json\"))\n",
    "        if not all_json:\n",
    "            raise FileNotFoundError(\"Aucun fichier .json trouvé dans DATA_DIR.\")\n",
    "        all_json.sort(key=lambda x: x.stat().st_size, reverse=True)\n",
    "        return all_json[0]\n",
    "    candidates.sort(key=lambda x: x.stat().st_size, reverse=True)\n",
    "    return candidates[0]\n",
    "\n",
    "json_path = find_shipsnet_json(DATA_DIR)\n",
    "print(\"JSON trouvé:\", json_path)\n",
    "\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "def get_key(d, keys):\n",
    "    for k in keys:\n",
    "        if k in d:\n",
    "            return k\n",
    "    return None\n",
    "\n",
    "x_key = get_key(data, [\"data\", \"X\", \"x\", \"images\"])\n",
    "y_key = get_key(data, [\"labels\", \"y\", \"Y\", \"target\", \"targets\"])\n",
    "\n",
    "if x_key is None or y_key is None:\n",
    "    raise KeyError(f\"Impossible d'identifier les clés X/y. Clés disponibles: {list(data.keys())}\")\n",
    "\n",
    "X_raw = np.array(data[x_key])\n",
    "y_raw = np.array(data[y_key])\n",
    "\n",
    "print(\"X_raw shape:\", X_raw.shape, \"dtype:\", X_raw.dtype)\n",
    "print(\"y_raw shape:\", y_raw.shape, \"unique:\", np.unique(y_raw, return_counts=True))\n",
    "\n",
    "# Reshape si flatten\n",
    "if X_raw.ndim == 2:\n",
    "    n, d = X_raw.shape\n",
    "    if d == 80 * 80 * 3:\n",
    "        H, W, C = 80, 80, 3\n",
    "    else:\n",
    "        if d % 3 != 0:\n",
    "            raise ValueError(f\"Dimension flatten inattendue: {d} (pas divisible par 3).\")\n",
    "        hw = d // 3\n",
    "        s = int(round(np.sqrt(hw)))\n",
    "        if s * s != hw:\n",
    "            raise ValueError(f\"Impossible d'inférer H=W depuis hw={hw}.\")\n",
    "        H, W, C = s, s, 3\n",
    "    X = X_raw.reshape(n, H, W, C)\n",
    "elif X_raw.ndim == 4:\n",
    "    X = X_raw\n",
    "    H, W, C = X.shape[1], X.shape[2], X.shape[3]\n",
    "else:\n",
    "    raise ValueError(f\"Format X_raw inattendu: ndim={X_raw.ndim}\")\n",
    "\n",
    "X = X.astype(\"float32\")\n",
    "y = y_raw.astype(\"int64\")\n",
    "\n",
    "print(\"X shape:\", X.shape, \"range:\", (X.min(), X.max()))\n",
    "print(\"y shape:\", y.shape, \"classes:\", np.unique(y))\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i in range(6):\n",
    "    plt.subplot(1, 6, i + 1)\n",
    "    img = X[i]\n",
    "    # si valeurs 0..255, afficher en uint8\n",
    "    if img.max() > 1.5:\n",
    "        img = img.astype(\"uint8\")\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(int(y[i]))\n",
    "plt.suptitle(\"Exemples (label 0/1)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbc612d",
   "metadata": {},
   "source": [
    "## 3. Split train/val/test et prétraitement ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b751a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "\n",
    "# Split stratifié : train 70%, val 15%, test 15%\n",
    "X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=SEED, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.50, random_state=SEED, stratify=y_tmp\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Val  :\", X_val.shape, y_val.shape)\n",
    "print(\"Test :\", X_test.shape, y_test.shape)\n",
    "\n",
    "y_train_oh = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_val_oh   = keras.utils.to_categorical(y_val, NUM_CLASSES)\n",
    "y_test_oh  = keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "preprocess = keras.applications.resnet50.preprocess_input\n",
    "\n",
    "def make_ds(X_arr, y_arr_oh, training: bool):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X_arr, y_arr_oh))\n",
    "    if training:\n",
    "        ds = ds.shuffle(2048, seed=SEED, reshuffle_each_iteration=True)\n",
    "    ds = ds.map(lambda x, y: (tf.image.resize(x, IMG_SIZE), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.map(lambda x, y: (preprocess(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = make_ds(X_train, y_train_oh, training=True)\n",
    "val_ds   = make_ds(X_val,   y_val_oh,   training=False)\n",
    "test_ds  = make_ds(X_test,  y_test_oh,  training=False)\n",
    "\n",
    "xb, yb = next(iter(train_ds))\n",
    "print(\"Batch X:\", xb.shape, xb.dtype, \"Batch y:\", yb.shape, yb.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ed653d",
   "metadata": {},
   "source": [
    "## 4. Modèle : ResNet50 + tête Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d26700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet50_transfer(num_classes=2, input_shape=(224, 224, 3), dropout=0.3):\n",
    "    inputs = L.Input(shape=input_shape)\n",
    "\n",
    "    base = keras.applications.ResNet50(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=inputs\n",
    "    )\n",
    "    base.trainable = False  # Phase 1: on gèle ResNet\n",
    "\n",
    "    x = base.output\n",
    "    x = L.GlobalAveragePooling2D()(x)\n",
    "    x = L.Dense(256, activation=\"relu\")(x)\n",
    "    x = L.Dropout(dropout)(x)\n",
    "    outputs = L.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name=\"resnet50_shipsnet\")\n",
    "    return model, base\n",
    "\n",
    "model_ship, base_model = build_resnet50_transfer(num_classes=NUM_CLASSES)\n",
    "model_ship.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efefa876",
   "metadata": {},
   "source": [
    "## 5. Entraînement — Phase 1 (head-only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5911467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ship.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-6),\n",
    "]\n",
    "\n",
    "history_1 = model_ship.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c239a9de",
   "metadata": {},
   "source": [
    "### Courbes (Phase 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7351e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(hist, title_prefix=\"\"):\n",
    "    plt.figure()\n",
    "    plt.plot(hist.history[\"loss\"])\n",
    "    plt.plot(hist.history[\"val_loss\"])\n",
    "    plt.legend([\"train\", \"val\"])\n",
    "    plt.title(f\"{title_prefix}Loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(hist.history[\"accuracy\"])\n",
    "    plt.plot(hist.history[\"val_accuracy\"])\n",
    "    plt.legend([\"train\", \"val\"])\n",
    "    plt.title(f\"{title_prefix}Accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history_1, title_prefix=\"Phase 1 — \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5c252b",
   "metadata": {},
   "source": [
    "## 6. Fine-tuning — Phase 2 (dé-gel partiel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b657bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonnes pratiques:\n",
    "# - dé-geler uniquement le haut du backbone\n",
    "# - geler BatchNorm (souvent recommandé)\n",
    "# - recompiler avec un LR plus faible\n",
    "\n",
    "base_model.trainable = True\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    if isinstance(layer, L.BatchNormalization):\n",
    "        layer.trainable = False\n",
    "\n",
    "fine_tune_from = None\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    if \"conv5\" in layer.name:\n",
    "        fine_tune_from = i\n",
    "        break\n",
    "\n",
    "if fine_tune_from is None:\n",
    "    fine_tune_from = int(len(base_model.layers) * 2 / 3)\n",
    "\n",
    "for layer in base_model.layers[:fine_tune_from]:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(\"Fine-tune from layer index:\", fine_tune_from, \"/\", len(base_model.layers))\n",
    "print(\"Base trainable layers:\", sum(l.trainable for l in base_model.layers), \"/\", len(base_model.layers))\n",
    "\n",
    "model_ship.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_2 = model_ship.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=8,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af07e4f",
   "metadata": {},
   "source": [
    "### Courbes (Phase 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a761e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_2, title_prefix=\"Phase 2 — \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81934b94",
   "metadata": {},
   "source": [
    "## 7. Évaluation finale (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb353d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model_ship.evaluate(test_ds, verbose=1)\n",
    "print(f\"Test loss: {test_loss:.4f} | Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "y_prob = model_ship.predict(test_ds, verbose=0)\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"no-ship\", \"ship\"]))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"no-ship\", \"ship\"])\n",
    "disp.plot(values_format=\"d\")\n",
    "plt.title(\"Confusion matrix (test)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a2e85",
   "metadata": {},
   "source": [
    "## 8. Sauvegarde du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ff34c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT_DIR = Path(\"export_resnet50_shipsnet\")\n",
    "EXPORT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "model_path = EXPORT_DIR / \"model_ship.keras\"\n",
    "model_ship.save(model_path)\n",
    "print(\"Modèle sauvegardé:\", model_path.resolve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
