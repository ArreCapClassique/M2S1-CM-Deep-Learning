{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc5a0ffc",
   "metadata": {},
   "source": [
    "# TD2 : Réseaux de neurones convolutionnels — Notebook optimisé (Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fb3acb",
   "metadata": {},
   "source": [
    "**Objectif :** ce notebook suit *exactement* la structure et l'intitulé des sous‑questions du PDF, avec **une sous‑question par cellule de code**, prêt à être exécuté sur **Google Colab**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870d4f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Préparation de l'environnement ---\n",
    "# Notebook conçu pour être exécutable \"Run all\" dans Google Colab.\n",
    "# En local, assurez-vous d'avoir TensorFlow et TensorFlow Datasets installés.\n",
    "#\n",
    "# (Optionnel - Colab) Si besoin, décommentez :\n",
    "# !pip -q install -U tensorflow tensorflow_datasets matplotlib\n",
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers as L\n",
    "\n",
    "# Reproductibilité (dans la limite des ops GPU non-déterministes)\n",
    "SEED = 42\n",
    "keras.utils.set_random_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "print(\"TF:\", tf.__version__)\n",
    "print(\"TFDS:\", tfds.__version__)\n",
    "print(\"Devices:\", tf.config.list_logical_devices())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8882a754",
   "metadata": {},
   "source": [
    "# Exercice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d89cdc",
   "metadata": {},
   "source": [
    "### 1. Charger le dataset CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2834c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 1 — 1. Charger le dataset CIFAR-10 (train/val/test)\n",
    "# Bonne pratique : ne pas utiliser le test comme validation (évite la fuite de données).\n",
    "(ds_train, ds_val, ds_test), ds_info = tfds.load(\n",
    "    \"cifar10\",\n",
    "    split=[\"train[:90%]\", \"train[90%:]\", \"test\"],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")\n",
    "\n",
    "num_classes = ds_info.features[\"label\"].num_classes\n",
    "input_shape = ds_info.features[\"image\"].shape\n",
    "print(\n",
    "    \"Classes:\",\n",
    "    num_classes,\n",
    "    \"| Input shape:\",\n",
    "    input_shape,\n",
    "    \"| Train:\",\n",
    "    tf.data.experimental.cardinality(ds_train).numpy(),\n",
    "    \"| Val:\",\n",
    "    tf.data.experimental.cardinality(ds_val).numpy(),\n",
    "    \"| Test:\",\n",
    "    tf.data.experimental.cardinality(ds_test).numpy(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fadf2b",
   "metadata": {},
   "source": [
    "### 2. Préparer le dataset pour l’apprentissage : normaliser les images, encoder les sorties pour un réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccc65c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 1 — 2. Préparation (normalisation + encodage one-hot)\n",
    "def preprocess_ex1(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    label = tf.one_hot(label, depth=num_classes)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "BATCH = 128\n",
    "\n",
    "ds_train_prep = (\n",
    "    ds_train.map(preprocess_ex1, num_parallel_calls=AUTOTUNE)\n",
    "    .cache()\n",
    "    .shuffle(10_000, seed=SEED, reshuffle_each_iteration=True)\n",
    "    .batch(BATCH)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "ds_val_prep = (\n",
    "    ds_val.map(preprocess_ex1, num_parallel_calls=AUTOTUNE)\n",
    "    .cache()\n",
    "    .batch(BATCH)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "ds_test_prep = (\n",
    "    ds_test.map(preprocess_ex1, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(BATCH)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62661161",
   "metadata": {},
   "source": [
    "### 3. Implémenter et tester l’architecture suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96d5c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 1 — 3. CNN de base selon la spécification\n",
    "def build_cnn_ex1(input_shape=(32, 32, 3), num_classes=10):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            L.Input(shape=input_shape),\n",
    "            L.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "            L.MaxPooling2D(2),\n",
    "            L.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "            L.MaxPooling2D(2),\n",
    "            L.Flatten(),\n",
    "            L.Dense(256, activation=\"relu\"),\n",
    "            L.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "model_ex1 = build_cnn_ex1(input_shape=input_shape, num_classes=num_classes)\n",
    "model_ex1.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model_ex1.summary()\n",
    "history_ex1 = model_ex1.fit(\n",
    "    ds_train_prep, validation_data=ds_val_prep, epochs=10, verbose=2\n",
    ")\n",
    "\n",
    "\n",
    "# Évaluation finale sur le test\n",
    "test_loss, test_acc = model_ex1.evaluate(ds_test_prep, verbose=0)\n",
    "print(f\"Test — loss: {test_loss:.4f} | acc: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1166dc7",
   "metadata": {},
   "source": [
    "### 4. Comparer les résultats de l’apprentissage avec les MLP développés dans le TD précédent, en performance et en nombre de paramètres. Evaluer la capacité de ce réseau à généraliser de cette architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e80c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 1 — 4. Comparaison (indicative)\n",
    "mlp_params = None  # Remplacez par votre valeur du TD précédent\n",
    "mlp_val_acc = None  # Remplacez par votre valeur du TD précédent\n",
    "\n",
    "cnn_params = model_ex1.count_params()\n",
    "cnn_val_acc = history_ex1.history.get(\"val_accuracy\", [None])[-1]\n",
    "print(f\"[CNN] params={cnn_params:,} | val_acc={cnn_val_acc}\")\n",
    "print(f\"[MLP] params={mlp_params} | val_acc={mlp_val_acc}\")\n",
    "print(\n",
    "    \"Observation: le CNN exploite la structure spatiale et généralise souvent mieux qu’un MLP de taille comparable.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c21135f",
   "metadata": {},
   "source": [
    "### 5. Modifier l’architecture précédente pour améliorer les résultats obtenus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d52c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 1 — 5. CNN amélioré\n",
    "data_aug = keras.Sequential(\n",
    "    [\n",
    "        L.RandomFlip(\"horizontal\"),\n",
    "        L.RandomRotation(0.05),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def build_cnn_ex1_improved(input_shape=(32, 32, 3), num_classes=10):\n",
    "    inputs = L.Input(shape=input_shape)\n",
    "    x = data_aug(inputs)\n",
    "    x = L.Conv2D(32, 3, padding=\"same\", activation=None)(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.ReLU()(x)\n",
    "    x = L.MaxPooling2D(2)(x)\n",
    "    x = L.Conv2D(64, 3, padding=\"same\", activation=None)(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.ReLU()(x)\n",
    "    x = L.MaxPooling2D(2)(x)\n",
    "    x = L.Conv2D(128, 3, padding=\"same\", activation=None)(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.ReLU()(x)\n",
    "    x = L.GlobalAveragePooling2D()(x)\n",
    "    x = L.Dropout(0.3)(x)\n",
    "    outputs = L.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model_ex1_imp = build_cnn_ex1_improved(input_shape=input_shape, num_classes=num_classes)\n",
    "model_ex1_imp.compile(\n",
    "    optimizer=keras.optimizers.Adam(3e-4),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model_ex1_imp.summary()\n",
    "history_ex1_imp = model_ex1_imp.fit(\n",
    "    ds_train_prep, validation_data=ds_val_prep, epochs=10, verbose=2\n",
    ")\n",
    "\n",
    "# Évaluation finale sur le test\n",
    "test_loss, test_acc = model_ex1_imp.evaluate(ds_test_prep, verbose=0)\n",
    "print(f\"Test (improved) — loss: {test_loss:.4f} | acc: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d843ff42",
   "metadata": {},
   "source": [
    "# Exercice 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5799cdd",
   "metadata": {},
   "source": [
    "### 1. Télécharger le dataset ‘stanford_dogs’ directement depuis votre notebook :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08af3c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 2 — 1. Télécharger le dataset ‘stanford_dogs’\n",
    "(ds_train_dogs, ds_test_dogs), ds_info_dogs = tfds.load(\n",
    "    \"stanford_dogs\", split=[\"train\", \"test\"], with_info=True, as_supervised=True\n",
    ")\n",
    "print(ds_info_dogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38125df0",
   "metadata": {},
   "source": [
    "### 2. Récupérez le nombre de classes à partir des informations. Combien y at’il de classes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3585bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 2 — 2. Nombre de classes\n",
    "num_classes_dogs = ds_info_dogs.features[\"label\"].num_classes\n",
    "print(\"Nombre de classes (stanford_dogs):\", num_classes_dogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bc61c8",
   "metadata": {},
   "source": [
    "### 3. Visualisez les premières images du dataset à l’aide de la méthode show_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dbcc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 2 — 3. Visualisation d'exemples\n",
    "tfds.visualization.show_examples(ds_train_dogs, ds_info_dogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebdfe92",
   "metadata": {},
   "source": [
    "### 4. Récupérez la première image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0627f8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 2 — 4. Récupérer la première image\n",
    "sample_image, sample_label = next(iter(ds_train_dogs.take(1)))\n",
    "print(\n",
    "    \"Image dtype/shape:\",\n",
    "    sample_image.dtype,\n",
    "    sample_image.shape,\n",
    "    \"| Label:\",\n",
    "    sample_label.numpy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5edb11f",
   "metadata": {},
   "source": [
    "### 5. Convertissez cette image en grayscale (nécessite d’installer tensorflow_io) avec rgb_to_grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f4b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 2 — 5. Conversion en niveaux de gris (TensorFlow standard)\n",
    "gray = tf.image.rgb_to_grayscale(tf.cast(sample_image, tf.float32))\n",
    "print(\"Grayscale shape:\", gray.shape)\n",
    "plt.imshow(tf.squeeze(gray).numpy(), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da049f0e",
   "metadata": {},
   "source": [
    "### 6. ... Ajoutez une dimension avec expand_dims, puis vérifiez le résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa44b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 2 — 6. Ajouter la dimension batch\n",
    "print(\"Avant:\", gray.shape)\n",
    "gray_batched = tf.expand_dims(gray, axis=0)\n",
    "print(\"Après :\", gray_batched.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5415f9",
   "metadata": {},
   "source": [
    "### 7. Définissez un noyau de convolution ... 3x3 en float32 (valeurs manuelles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428110eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 2 — 7. Noyau 3x3 manuel\n",
    "import numpy as np\n",
    "\n",
    "kernel_2d = np.array(\n",
    "    [\n",
    "        [-1.0, 0.0, 1.0],\n",
    "        [-2.0, 0.0, 2.0],\n",
    "        [-1.0, 0.0, 1.0],\n",
    "    ],\n",
    "    dtype=np.float32,\n",
    ")\n",
    "print(kernel_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dccb8a",
   "metadata": {},
   "source": [
    "### 8. ... appliquer le noyau avec tf.nn.conv2d (stride=1, padding='SAME'), puis visualiser en grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3257f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 2 — 8. Application du filtre via conv2d\n",
    "kernel_4d = tf.reshape(kernel_2d, [3, 3, 1, 1])\n",
    "filtered = tf.nn.conv2d(gray_batched, kernel_4d, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "filtered_img = tf.squeeze(filtered, axis=0)\n",
    "plt.imshow(tf.squeeze(filtered_img).numpy(), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ce88ec",
   "metadata": {},
   "source": [
    "### 9. ... implémente un filtre de Sobel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132a0f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 2 — 9. Filtre de Sobel\n",
    "sobel_x = tf.reshape(\n",
    "    tf.constant([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=tf.float32), [3, 3, 1, 1]\n",
    ")\n",
    "sobel_y = tf.reshape(\n",
    "    tf.constant([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=tf.float32), [3, 3, 1, 1]\n",
    ")\n",
    "gx = tf.nn.conv2d(gray_batched, sobel_x, strides=1, padding=\"SAME\")\n",
    "gy = tf.nn.conv2d(gray_batched, sobel_y, strides=1, padding=\"SAME\")\n",
    "mag = tf.sqrt(tf.square(gx) + tf.square(gy) + 1e-6)\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Gx\")\n",
    "plt.imshow(tf.squeeze(gx), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Gy\")\n",
    "plt.imshow(tf.squeeze(gy), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Magnitude\")\n",
    "plt.imshow(tf.squeeze(mag), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65355d93",
   "metadata": {},
   "source": [
    "# Exercice 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6190a5",
   "metadata": {},
   "source": [
    "### 1. Télécharger le dataset ‘stanford_dogs‘ depuis votre notebook avec les mêmes options que dans l’exercice précédent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390568da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 3 — 1. Télécharger stanford_dogs\n",
    "(ds_train_dogs2, ds_test_dogs2), ds_info_dogs2 = tfds.load(\n",
    "    \"stanford_dogs\", split=[\"train\", \"test\"], with_info=True, as_supervised=True\n",
    ")\n",
    "n_classes = ds_info_dogs2.features[\"label\"].num_classes\n",
    "print(\"Classes:\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535b97ce",
   "metadata": {},
   "source": [
    "### 2. ... convertir les labels avec un encodage ‘one_hot’. Pour réaliser cela, utiliser map et tf.one_hot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d2673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 3 — 2. One-hot des labels\n",
    "def one_hot_map(image, label):\n",
    "    return image, tf.one_hot(label, depth=n_classes)\n",
    "\n",
    "\n",
    "dogs_train_oh = ds_train_dogs2.map(one_hot_map, num_parallel_calls=AUTOTUNE)\n",
    "dogs_test_oh = ds_test_dogs2.map(one_hot_map, num_parallel_calls=AUTOTUNE)\n",
    "for img, lab in dogs_train_oh.take(1):\n",
    "    print(\"Image:\", img.shape, \"| Label one-hot shape:\", lab.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db7a55e",
   "metadata": {},
   "source": [
    "### 3. ... images 128x128 + normaliser [0,1] via Sequential(Resizing, Rescaling). Tester d’abord sur une image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c1e3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 3 — 3. Préprocessing (test sur une image)\n",
    "preproc = keras.Sequential(\n",
    "    [\n",
    "        L.Resizing(128, 128),\n",
    "        L.Rescaling(1.0 / 255.0),\n",
    "    ]\n",
    ")\n",
    "img0, lab0 = next(iter(dogs_train_oh.take(1)))\n",
    "img0_p = preproc(tf.expand_dims(img0, 0))\n",
    "print(\n",
    "    \"Avant:\",\n",
    "    img0.shape,\n",
    "    \"Après:\",\n",
    "    img0_p.shape,\n",
    "    \"min/max:\",\n",
    "    tf.reduce_min(img0_p).numpy(),\n",
    "    tf.reduce_max(img0_p).numpy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45493c32",
   "metadata": {},
   "source": [
    "### 4. Appliquez les transformations à l’ensemble du dataset à l’aide de la fonction map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9dd9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 3 — 4. Appliquer au dataset complet\n",
    "def pp_map(image, label_oh):\n",
    "    image = preproc(image)\n",
    "    return image, label_oh\n",
    "\n",
    "\n",
    "BATCH_DOGS = 64\n",
    "dogs_train_pp = (\n",
    "    dogs_train_oh.map(pp_map, num_parallel_calls=AUTOTUNE)\n",
    "    .cache()\n",
    "    .shuffle(5000)\n",
    "    .batch(BATCH_DOGS)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "dogs_test_pp = (\n",
    "    dogs_test_oh.map(pp_map, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(BATCH_DOGS)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "for img, lab in dogs_train_pp.take(1):\n",
    "    print(\"Batch:\", img.shape, lab.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5e498a",
   "metadata": {},
   "source": [
    "### 5. ... augmentation de données via couches de preprocessing (expérimentez sur une image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fa1bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 3 — 5. Augmentations sur une image\n",
    "aug = keras.Sequential(\n",
    "    [\n",
    "        L.RandomFlip(\"horizontal\"),\n",
    "        L.RandomRotation(0.1),\n",
    "        L.RandomContrast(0.1),\n",
    "        L.RandomZoom(0.1),\n",
    "    ]\n",
    ")\n",
    "augmented = aug(img0_p, training=True)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original (pp)\")\n",
    "plt.imshow(tf.squeeze(img0_p))\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Augmentée\")\n",
    "plt.imshow(tf.squeeze(augmented))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe58413e",
   "metadata": {},
   "source": [
    "# Exercice 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ee8429",
   "metadata": {},
   "source": [
    "### 1. Téléchargez et préparez le dataset ‘beans’ pour l’entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99b280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 4 — 1. Télécharger et préparer 'beans'\n",
    "(ds_train_beans, ds_val_beans, ds_test_beans), ds_info_beans = tfds.load(\n",
    "    \"beans\", split=[\"train\", \"validation\", \"test\"], with_info=True, as_supervised=True\n",
    ")\n",
    "n_classes_beans = ds_info_beans.features[\"label\"].num_classes\n",
    "input_shape_beans = ds_info_beans.features[\"image\"].shape\n",
    "\n",
    "\n",
    "def pp_beans(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, tf.one_hot(label, depth=n_classes_beans)\n",
    "\n",
    "\n",
    "BATCH_BEANS = 64\n",
    "train_beans = (\n",
    "    ds_train_beans.map(pp_beans, num_parallel_calls=AUTOTUNE)\n",
    "    .cache()\n",
    "    .shuffle(5000)\n",
    "    .batch(BATCH_BEANS)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "val_beans = (\n",
    "    ds_val_beans.map(pp_beans, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(BATCH_BEANS)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "test_beans = (\n",
    "    ds_test_beans.map(pp_beans, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(BATCH_BEANS)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "print(\"Beans | classes:\", n_classes_beans, \"| input:\", input_shape_beans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e8fbfb",
   "metadata": {},
   "source": [
    "### 2. Implémentez une fonction qui retourne un réseau de neurones convolutionnel (style VGG, 3 blocs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a45716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 4 — 2. VGG-like (3 blocs)\n",
    "def build_vgg_beans(input_shape=(None, None, 3), num_classes=3):\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            L.Input(shape=input_shape),\n",
    "            # Bloc 1\n",
    "            L.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "            L.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "            L.MaxPooling2D(2),\n",
    "            # Bloc 2\n",
    "            L.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "            L.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "            L.MaxPooling2D(2),\n",
    "            # Bloc 3\n",
    "            L.Conv2D(128, 3, padding=\"same\", activation=\"relu\"),\n",
    "            L.Conv2D(128, 3, padding=\"same\", activation=\"relu\"),\n",
    "            L.MaxPooling2D(2),\n",
    "            L.GlobalAveragePooling2D(),\n",
    "            L.Dense(128, activation=\"relu\"),\n",
    "            L.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "model_beans = build_vgg_beans(\n",
    "    input_shape=input_shape_beans, num_classes=n_classes_beans\n",
    ")\n",
    "model_beans.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model_beans.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492336d8",
   "metadata": {},
   "source": [
    "### 3. Compilez votre réseau ... La première couche convolutionnelle doit contenir 896 paramètres et la seconde 9248. Pourquoi ces nombres ? Comment calculer le nombre de paramètres d’une couche convolutionnelle ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca23e14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 4 — 3. Vérifier les paramètres\n",
    "# Formule: params = (Kh * Kw * Cin + bias) * Cout ; bias=1 si bias présent.\n",
    "# Conv1: (3*3*3 + 1) * 32 = 896 ; Conv2: (3*3*32 + 1) * 32 = 9248\n",
    "conv1_weights = model_beans.layers[1].count_params()\n",
    "conv2_weights = model_beans.layers[2].count_params()\n",
    "print(\"Conv1 params (attendu 896):\", conv1_weights)\n",
    "print(\"Conv2 params (attendu 9248):\", conv2_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25999f89",
   "metadata": {},
   "source": [
    "### 4. Entrainez le sur le dataset avec fit pendant 50 epochs ... récupérer history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15d4eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 4 — 4. Entraînement (50 epochs) avec validation 10%\n",
    "EPOCHS = 50\n",
    "history_beans = model_beans.fit(\n",
    "    train_beans, validation_data=val_beans, epochs=EPOCHS, verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3635a09",
   "metadata": {},
   "source": [
    "### 5. ... tracer des courbes d’évolution de la loss et de l’accuracy, sur les ensembles d’entrainement et de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2912ea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 4 — 5. Tracer loss/accuracy\n",
    "epochs = range(1, len(history_beans.history[\"loss\"]) + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs, history_beans.history[\"loss\"], label=\"loss (train)\")\n",
    "plt.plot(epochs, history_beans.history[\"val_loss\"], label=\"loss (val)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Beans — Loss\")\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(epochs, history_beans.history[\"accuracy\"], label=\"acc (train)\")\n",
    "plt.plot(epochs, history_beans.history[\"val_accuracy\"], label=\"acc (val)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Beans — Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a395ab7d",
   "metadata": {},
   "source": [
    "### 6. Pour finir, testez le réseau sur des données non observées lors de l’entrainement. Le résultat est-il satisfaisant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717e6ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 4 — 6. Évaluation sur le test (non vu)\n",
    "test_loss, test_acc = model_beans.evaluate(test_beans, verbose=0)\n",
    "print(f\"Test — loss: {test_loss:.4f} | acc: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df05717",
   "metadata": {},
   "source": [
    "# Exercice 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3a6189",
   "metadata": {},
   "source": [
    "### 1. Sans changer l’architecture globale que vous aviez choisi, améliorez les performances de votre réseau ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00596eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 5 — 1. Amélioration sans changer l'architecture globale\n",
    "data_aug_beans = keras.Sequential(\n",
    "    [\n",
    "        L.RandomFlip(\"horizontal\"),\n",
    "        L.RandomRotation(0.1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def build_vgg_beans_improved(input_shape=(None, None, 3), num_classes=3):\n",
    "    inputs = L.Input(shape=input_shape)\n",
    "    x = data_aug_beans(inputs)\n",
    "    # Bloc 1\n",
    "    x = L.Conv2D(32, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.ReLU()(x)\n",
    "    x = L.Conv2D(32, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.ReLU()(x)\n",
    "    x = L.MaxPooling2D(2)(x)\n",
    "    x = L.Dropout(0.2)(x)\n",
    "    # Bloc 2\n",
    "    x = L.Conv2D(64, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.ReLU()(x)\n",
    "    x = L.Conv2D(64, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.ReLU()(x)\n",
    "    x = L.MaxPooling2D(2)(x)\n",
    "    x = L.Dropout(0.3)(x)\n",
    "    # Bloc 3\n",
    "    x = L.Conv2D(128, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.ReLU()(x)\n",
    "    x = L.Conv2D(128, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.ReLU()(x)\n",
    "    x = L.GlobalAveragePooling2D()(x)\n",
    "    x = L.Dropout(0.4)(x)\n",
    "    outputs = L.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model_beans_imp = build_vgg_beans_improved(\n",
    "    input_shape=input_shape_beans, num_classes=n_classes_beans\n",
    ")\n",
    "model_beans_imp.compile(\n",
    "    optimizer=keras.optimizers.Adam(3e-4),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model_beans_imp.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c522d87",
   "metadata": {},
   "source": [
    "### 2. Entrainez à nouveau votre réseau et réglez les differents paramètres pour obtenir un apprentissage satisfaisant, avec des courbes d’entrainement et de validation proches l’une de l’autre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3eb9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 5 — 2. Entraînement + visualisation\n",
    "EPOCHS_IMP = 30\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        patience=6, restore_best_weights=True, monitor=\"val_accuracy\"\n",
    "    )\n",
    "]\n",
    "history_beans_imp = model_beans_imp.fit(\n",
    "    train_beans,\n",
    "    validation_data=val_beans,\n",
    "    epochs=EPOCHS_IMP,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2,\n",
    ")\n",
    "epochs_imp = range(1, len(history_beans_imp.history[\"loss\"]) + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs_imp, history_beans_imp.history[\"loss\"], label=\"loss (train)\")\n",
    "plt.plot(epochs_imp, history_beans_imp.history[\"val_loss\"], label=\"loss (val)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Beans (amélioré) — Loss\")\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(epochs_imp, history_beans_imp.history[\"accuracy\"], label=\"acc (train)\")\n",
    "plt.plot(epochs_imp, history_beans_imp.history[\"val_accuracy\"], label=\"acc (val)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Beans (amélioré) — Accuracy\")\n",
    "plt.show()\n",
    "test_loss_imp, test_acc_imp = model_beans_imp.evaluate(test_beans, verbose=0)\n",
    "print(f\"[Amélioré] Test — loss: {test_loss_imp:.4f} | acc: {test_acc_imp:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "02_TD2_optimized_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
